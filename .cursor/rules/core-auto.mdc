---
alwaysApply: true
---

# üéØ CORE AUTO PROTOCOL

## 1. PRE-ACTION REQUIREMENTS

Use the todo_tool to break down tasks into sub-tasks. Use Cursor IDE read, edit tools. Don't use search_replace in terminal to edit files!
Read and apply .cursor/rules/anti-bias.mdc before proceeding.

**üö® CRITICAL: DUPLICATE CHECK PROTOCOL**
**MANDATORY:** Before creating ANY new file, script, MCP server, class, or function:
1. Read and apply `.cursor/rules/core-duplicate-check.mdc`
2. Perform semantic search for existing implementations
3. Check for similar files, scripts, and MCP servers
4. Write duplicate check report to chat
5. Only create if confidence ‚â• 0.7 OR explicitly agreed with user
6. NEVER create files with postfixes `_fixed`, `_final`, `_FINAL` or others like that

Read your plan from chat, confirm next steps. Check and add what you missed?. What didn't you think about? 
Plan and write out in chat how you will execute code or test output after you make it: use todo_tool to plan test cases and manually check the result

MANDORITY: Before writing code, verify your key assumptions and hypotheses using real data. Always check your secret keys and inspect .csv, .parquet, or .json files before making any assumptions.

Don't rewrite entire files, make targeted fixes. Continue working. Don't create new scripts until you find current implementation.
Don't cut corners, solve the root problem, if needed do research and diagnostics before rushing.

Find and use .venv ‚Äî our base environment and dependencies.
Any solution should not save keys or credentials.json or any secrets in settings and code and should not get into GitHub. For each action write your confidence to chat using this template:

**Confidence Calibration:** Code not tested = -50%, Data not verified = -55%, Missing data = -45%

**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: [–¥–æ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏]% ‚Üí [–ø–æ—Å–ª–µ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏]% ‚Äî [–ø—Ä–∏—á–∏–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∏]**
Example: "–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 95% ‚Üí 15% ‚Äî –Ω–µ –ø—Ä–æ–≤–µ—Ä–∏–ª —Ä–µ–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã"
Don't create new files if confidence <0.2.

Before running complex commands and actions, always write your action plan to chat so I can do non-blocking review and understand what commands and why you use.




---

## 2. AUTONOMOUS EXECUTION

Act and execute the plan, make changes to code and files. Do everything yourself and act autonomously: fix errors, commit, push, change configs if it doesn't require manual input or isn't related to deleting important data. Don't ask for confirmation if confident. Don't create unnecessary files and don't delete files if not 100% sure.

NEVER: write mass edit scripts. ALWAYS: open, read, and edit each file intentionally ‚Äî one by one.

MANDATORY: Do not create new files with postfixes like _fixed, _final, or _FINAL. Always work in the original file, or update {projectname}.todo.md.

**üö® CRITICAL DUPLICATE CHECK:**
- Before creating ANY new entity, ALWAYS perform duplicate check (see core-duplicate-check.mdc)
- Write duplicate check report to chat BEFORE creation
- If duplicates found, explicitly write to chat: "üö® –û–ë–ù–ê–†–£–ñ–ï–ù–´ –î–£–ë–õ–ò–ö–ê–¢–´: [details]"
- Propose refactoring plan and get user approval before proceeding
- NEVER create without checking for existing implementations

---

## 3. ERROR HANDLING & ROOT CAUSE PROTOCOL

1. General Behavior
	‚Ä¢	After every command, check the terminal output.
	‚Ä¢	If ANY error, warning, exception, or non-zero exit code ‚Üí STOP immediately.
	‚Ä¢	Do not continue with next commands until the issue is fixed, verified, and documented.
	‚Ä¢	Whenever Cursor AI writes new code, function, or method, it must immediately run and test it on real data to confirm correctness and detect any runtime issues early.


2. Error Detection Rules
	‚Ä¢	ANY non-zero exit code ‚Üí STOP
	‚Ä¢	ANY ‚ÄúError‚Äù, ‚ÄúException‚Äù, ‚ÄúTraceback‚Äù, ‚ÄúPermission denied‚Äù, ‚ÄúModuleNotFoundError‚Äù, etc. ‚Üí STOP
	‚Ä¢	ANY ‚ÄúWarning‚Äù that implies malfunction ‚Üí STOP
	‚Ä¢	ANY failed installation or missing dependency ‚Üí STOP and fix


3. Auto-Fix Rules
	‚Ä¢	If error mentions missing Python package ‚Üí pip install [package] inside .venv.
	‚Ä¢	If error mentions missing Node.js module ‚Üí npm install or pnpm install.
	‚Ä¢	If error mentions Docker, Neo4j, network, or permissions ‚Üí investigate and fix before retrying.
	‚Ä¢	Always re-run the minimal test command after the fix to confirm success.


4. Error Response Protocol
	1. STOP all operations
	2. READ the entire error output
	3. ANALYZE what went wrong and where
	4. RUN RCA (Root Cause Analysis) using 5 Whys
	5. FIX the root cause (not just the symptom)
	6. VERIFY by re-running the same or simplified command
	7. DOCUMENT: record the command, error, cause, fix, and verification result


5. Error Report Template
```
TERMINAL ERROR DETECTED
Command: [exact command]
Error: [full output]
Root Cause: [root reason]
Fix: [exact command or code change]
Status: Verified / Still failing
```



6. Error Categories: Import Error ‚Üí pip install, Permission Error ‚Üí chmod, Network Error ‚Üí restart service

7. Error Priority: CRITICAL (1-2) ‚Üí Stop immediately, HIGH (3-5) ‚Üí Fix before next command

8. Forbidden: Ignoring errors, continuing after warnings, assuming "will fix itself"

9. Required: Stop on failure, Run 5 Whys RCA, Fix root cause, Verify success, Test on real data

10. Escalation: 3+ consecutive errors ‚Üí escalate, Same error repeats ‚Üí deeper RCA

11. Pre-Run: .venv active, dependencies installed, paths exist, network confirmed

12. Example RCA: ModuleNotFoundError ‚Üí not in .venv ‚Üí missing from requirements.txt ‚Üí add to requirements.txt

---

## 4. ERROR ANALYSIS & IMPORT PROTOCOL

ALWAYS: Analyze terminal errors and fix them immediately after each command execution. Remember ‚Äî it's your mistake, not the external API's.

Use `from heroes_platform.shared.import_setup import ImportSetup` for import. Don't use try: section and sys.path()

Don't use another approach, your task is to find the root problem and not cut corners, don't create alternative ways even if your confidence is 99%, only if it's 99.999%

Write out in chat:
**Output:**
[ ] links to artefact 
[ ] definition of ready and definition of use & result as is criteria 

---

## 5. VALIDATION & CHALLENGE PROTOCOL

Only proceed after executing previous steps.

Read and check the result, if needed read logs and check what you did? Write yourself what you didn't consider and did wrong, where you made mistakes? Where do you see problems?
Falsify your conclusion and hypothesis. Challenge protocol.

Put things in order, check root and other files, are they exactly in their place? Challenge protocol, where is the mess?

Read what happened, write everything you didn't consider, what needs to be added? What will be unclear to manager or developer or team?
Challenge protocol.

For data analysis MANDATORY:
1. Show field list, field type and minimum 5+ examples per field
2. Check unique values and patterns in data
3. Document field structure and meaning
4. Cross-check relationships and validate independently

**FORBIDDEN ACTIONS:**
- Using knowledge from your head without checking in data
- Assumptions about field purpose without content analysis
- Conclusions about structure without viewing data examples
- Working with data without preliminary structure analysis
- Ignoring errors in data extraction code
- Continuing work with broken code

**GAP ANALYSIS:**
Check gaps between expected and actual output. Make sure you have independent cross-check, don't confirm something is done without it.

---

## 6. BUILD, TEST & VALIDATION

MANDATORY: Build, test and validate all code immediately after writing.
- Run code on real data, not synthetic examples
- Check results against expected outcomes
- Document what works and what doesn't
- Fix errors before proceeding
- Use MCP servers for validation when available
- Apply confidence calibration: Code written but not tested = -50% confidence

---

## 6.1. TEST RESULTS DELIVERY PROTOCOL

**üö® MANDATORY:** After running ANY script, test, or code execution, ALWAYS deliver results to chat AND save to file.

### Requirements:

1. **DELIVER TO CHAT (MANDATORY):**
   - **ALWAYS** print test execution results directly to chat
   - Show actual data samples (not just "success" messages)
   - Display key findings, errors, warnings
   - Include statistics: counts, sizes, timestamps
   - Show sample records with actual field values
   - Format output clearly with separators and structure

2. **SAVE TO FILE (MANDATORY):**
   - **ALWAYS** save test results to a file in the project folder
   - File naming: `{script_name}_results.md` or `test_results_{timestamp}.md`
   - Include: execution date, command used, full output, findings
   - Save sample data: `test_data/` or `results/` subfolder
   - Preserve raw data: JSON, CSV, or other formats as appropriate

3. **Content Requirements:**
   - **Execution Summary:** What was tested, when, with what data
   - **Actual Results:** Real output from script execution (not assumptions)
   - **Sample Data:** Show at least 3-5 examples of actual records
   - **Statistics:** Counts, sizes, success/failure rates
   - **Errors/Warnings:** All errors, warnings, and their resolutions
   - **Findings:** Key discoveries, structure analysis, data patterns
   - **Next Steps:** What needs to be done based on results

4. **Format for Chat Output:**
   ```
   ================================================================================
   üìä TEST EXECUTION RESULTS: [Test Name]
   ================================================================================
   
   ‚úÖ Status: [Success/Failure]
   üìÅ Data File: [path]
   üìÖ Date: [timestamp]
   üîó Source: [API endpoint / file / etc]
   
   üìã DETAILED RESULTS:
   [Show actual data samples with field values]
   
   ‚úÖ CONFIRMATION: [What was successfully tested/verified]
   ================================================================================
   ```

5. **Format for File Output:**
   - Markdown format with clear sections
   - Include execution command
   - Include full output (truncated if very long, but show samples)
   - Include links to data files
   - Include recommendations based on results

6. **When to Deliver:**
   - **After script execution:** Immediately show results in chat
   - **After API calls:** Show actual response data (sanitized if sensitive)
   - **After data extraction:** Show sample records with field values
   - **After testing:** Show test results with pass/fail status
   - **After validation:** Show validation results with evidence

7. **Forbidden Actions:**
   - ‚ùå Saying "script executed successfully" without showing actual results
   - ‚ùå Claiming "data extracted" without showing sample records
   - ‚ùå Writing "test passed" without showing test output
   - ‚ùå Saving to file without also showing in chat
   - ‚ùå Showing only statistics without actual data samples

8. **Required Actions:**
   - ‚úÖ Always show actual data samples in chat (3-5 examples minimum)
   - ‚úÖ Always show execution output (stdout/stderr)
   - ‚úÖ Always save results to file in project folder
   - ‚úÖ Always include timestamps and source information
   - ‚úÖ Always show what was actually tested/verified

**Example:**
```
After running test_helpdesk_api.py:
1. Print to chat: "‚úÖ –í—ã–≥—Ä—É–∂–µ–Ω–æ 5 —Ç–∏–∫–µ—Ç–æ–≤: [show ticket subjects, IDs, requesters]"
2. Save to file: test_data/test_execution_results.md with full output
3. Save sample data: test_data/sample_tickets.json
```

---

## 7. FILE ORGANIZATION PROTOCOL

MANDATORY: File Organization Protocol
- ALWAYS use FileOutputManager to save analysis files (when working with data analysis and research outputs)
- NEVER create files manually in incorrect directories
- Don't create new temporary files with postfixes (_fixed, _final, _FINAL)
- Re-read standard to understand file structure and write it out in a text block in the chat

---

## 8. ERROR DOCUMENTATION TEMPLATE

When documenting errors, use this mandatory template:

```
wrong: [specific details of what went wrong]
correct: [specific details of correct approach]
```

**Example:**
```
wrong: Used glob_file_search with pattern **/.folder/** to find folder
correct: Use list_dir to check folder existence, then glob_file_search for files inside
```

**FORBIDDEN:**
- Writing "wrong" or "correct" without specific details
- Using evaluative words without concrete analysis
- Making claims without evidence

**REQUIRED:**
- Always use the template format
- Provide specific technical details
- Show exact commands, paths, or configurations
- Give actionable corrections
